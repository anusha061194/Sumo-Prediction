{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filtered_df = pd.read_excel(\"C:/Users/anush/Desktop/Torikumi_New.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['Rikishi1_Kimarite_count'] = filtered_df.groupby(['Rikishi1','Kimarite']).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rikishi1_List = []\n",
    "Rikishi2_List = []\n",
    "rikishi1_df = pd.DataFrame(columns=['Rikishi1_Kimarite', 'Rikishi1_Winning_Kimarite_count'])\n",
    "for i in range(len(filtered_df)):\n",
    "    rikishi2_kimarite = str(filtered_df.iloc[i, 20]) + \"_\" + str(filtered_df.iloc[i, 16])\n",
    "    rikishi1_df.loc[i] = str(filtered_df.iloc[i, 5]) + \"_\" + str(filtered_df.iloc[i, 16]), filtered_df.iloc[i, 14]\n",
    "    if rikishi2_kimarite in rikishi1_df.values :\n",
    "        occur_len = len(rikishi1_df[rikishi1_df['Rikishi1_Kimarite'] == rikishi2_kimarite])\n",
    "        filtered_df.loc[i,['Rikishi2_Winning_Kimarite_count']] = occur_len\n",
    "    else :\n",
    "        occur_len = 0\n",
    "        filtered_df.loc[i,['Rikishi2_Winning_Kimarite_count']] = occur_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_excel(\"C:/Users/anush/Desktop/Torikumi_New.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filtered_df = pd.read_excel(filtered_df.to_excel(\"C:/Users/anush/Desktop/Torikumi_New.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical = (pd.notnull(filtered_df['Rikishi1_Winning_Kimarite_count'])) & (pd.notnull(filtered_df['Rikishi2_Winning_Kimarite_count'])) & (pd.notnull(filtered_df['Rikishi1_Losing_Kimarite_count'])) & (pd.notnull(filtered_df['Rikishi2_Losing_Kimarite_count']))  \n",
    "\n",
    "filtered_df = filtered_df[logical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: DTree\n",
      "    Inner loop:\n",
      ">acc=0.597, est=0.612, cfg={'criterion': 'gini', 'max_depth': 8}\n",
      ">acc=0.605, est=0.612, cfg={'criterion': 'entropy', 'max_depth': 9}\n",
      ">acc=0.606, est=0.607, cfg={'criterion': 'gini', 'max_depth': 7}\n",
      ">acc=0.609, est=0.608, cfg={'criterion': 'entropy', 'max_depth': 9}\n",
      ">acc=0.609, est=0.612, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      ">acc=0.612, est=0.609, cfg={'criterion': 'entropy', 'max_depth': 9}\n",
      ">acc=0.615, est=0.612, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      ">acc=0.622, est=0.612, cfg={'criterion': 'entropy', 'max_depth': 9}\n",
      ">acc=0.612, est=0.610, cfg={'criterion': 'entropy', 'max_depth': 9}\n",
      ">acc=0.606, est=0.615, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.609 (0.006)\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: GNB\n",
      "    Inner loop:\n",
      ">acc=0.556, est=0.546, cfg={'var_smoothing': 0.003511191734215131}\n",
      ">acc=0.549, est=0.546, cfg={'var_smoothing': 0.005336699231206307}\n",
      ">acc=0.549, est=0.547, cfg={'var_smoothing': 0.001}\n",
      ">acc=0.546, est=0.547, cfg={'var_smoothing': 0.001}\n",
      ">acc=0.539, est=0.547, cfg={'var_smoothing': 3.511191734215127e-05}\n",
      ">acc=0.541, est=0.547, cfg={'var_smoothing': 0.0006579332246575676}\n",
      ">acc=0.550, est=0.546, cfg={'var_smoothing': 0.0001873817422860383}\n",
      ">acc=0.541, est=0.547, cfg={'var_smoothing': 8.111308307896872e-05}\n",
      ">acc=0.545, est=0.547, cfg={'var_smoothing': 0.0015199110829529332}\n",
      ">acc=0.550, est=0.546, cfg={'var_smoothing': 0.0005336699231206307}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.578 (0.032)\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: KNN\n",
      "    Inner loop:\n",
      ">acc=0.603, est=0.602, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.599, est=0.602, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.606, est=0.599, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.604, est=0.598, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.604, est=0.601, cfg={'n_neighbors': 9, 'p': 2}\n",
      ">acc=0.595, est=0.600, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.591, est=0.600, cfg={'n_neighbors': 7, 'p': 1}\n",
      ">acc=0.599, est=0.600, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.601, est=0.601, cfg={'n_neighbors': 9, 'p': 2}\n",
      ">acc=0.598, est=0.603, cfg={'n_neighbors': 9, 'p': 1}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.585 (0.028)\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: LR\n",
      "    Inner loop:\n",
      ">acc=0.598, est=0.603, cfg={'C': 0.001, 'penalty': 'l2'}\n",
      ">acc=0.603, est=0.602, cfg={'C': 0.001, 'penalty': 'l2'}\n",
      ">acc=0.605, est=0.602, cfg={'C': 0.001, 'penalty': 'l2'}\n",
      ">acc=0.612, est=0.601, cfg={'C': 0.001, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anush\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\anush\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.605, est=0.602, cfg={'C': 0.001, 'penalty': 'l2'}\n",
      ">acc=0.599, est=0.602, cfg={'C': 0.01, 'penalty': 'l2'}\n",
      ">acc=0.599, est=0.602, cfg={'C': 0.001, 'penalty': 'l2'}\n",
      ">acc=0.605, est=0.602, cfg={'C': 0.001, 'penalty': 'l2'}\n",
      ">acc=0.607, est=0.601, cfg={'C': 0.001, 'penalty': 'l2'}\n",
      ">acc=0.588, est=0.603, cfg={'C': 0.001, 'penalty': 'l2'}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.589 (0.026)\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: SVM\n",
      "    Inner loop:\n",
      ">acc=0.571, est=0.584, cfg={'kernel': 'linear'}\n",
      ">acc=0.579, est=0.583, cfg={'kernel': 'linear'}\n",
      ">acc=0.573, est=0.584, cfg={'kernel': 'linear'}\n",
      ">acc=0.586, est=0.583, cfg={'kernel': 'linear'}\n",
      ">acc=0.586, est=0.583, cfg={'kernel': 'linear'}\n",
      ">acc=0.586, est=0.582, cfg={'kernel': 'linear'}\n",
      ">acc=0.584, est=0.583, cfg={'kernel': 'linear'}\n",
      ">acc=0.591, est=0.582, cfg={'kernel': 'linear'}\n",
      ">acc=0.587, est=0.582, cfg={'kernel': 'linear'}\n",
      ">acc=0.586, est=0.582, cfg={'kernel': 'linear'}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.588 (0.023)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create dataset\n",
    "#X_scaled, y = make_classification(n_samples=59817, n_features=24, random_state=1, n_informative=2, n_redundant=22)\n",
    "# configure the cross-validation procedure\n",
    "\n",
    "X = filtered_df.loc[:, ['Rikishi1_Winning_Kimarite_count', 'Rikishi2_Winning_Kimarite_count', 'Rikishi1_Losing_Kimarite_count', 'Rikishi2_Losing_Kimarite_count']]\n",
    "scaler = StandardScaler(copy=True, with_mean=False, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "y = filtered_df.loc[:, 'Label']  # labels, outcomes for first sumo (1 for wins, 0 for losses)\n",
    "\n",
    "# define the model\n",
    "clf1 = LogisticRegression(multi_class='multinomial',solver='newton-cg',random_state=1)\n",
    "clf2 = KNeighborsClassifier(algorithm='ball_tree',leaf_size=20)\n",
    "clf3 = DecisionTreeClassifier(random_state=1)\n",
    "clf4 = GaussianNB()  \n",
    "clf5 = SVC()\n",
    "    \n",
    "# define search space\n",
    "param_grid1 = [{'penalty': ['l2'],'C': np.power(10., np.arange(-4, 4))}]\n",
    "param_grid2 = [{'n_neighbors': list(range(1, 10)),'p': [1, 2]}]\n",
    "param_grid3 = [{'max_depth': list(range(1, 10)) + [None],'criterion': ['gini', 'entropy']}]\n",
    "param_grid4 = [{'var_smoothing': np.logspace(0,-9, num=100)}]\n",
    "param_grid5 = [{'kernel': ['linear']}]\n",
    "\n",
    "cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# define search    \n",
    "gridcvs = {}\n",
    "for pgrid, est, name in zip((param_grid1, param_grid2, param_grid3, param_grid4, param_grid5),(clf1, clf2, clf3, clf4, clf5),('LR', 'KNN', 'DTree', 'GNB', 'SVM')):\n",
    "    search = GridSearchCV(estimator=est,param_grid=pgrid,scoring='accuracy',n_jobs=-1,cv=cv_inner,verbose=0,refit=True)\n",
    "    gridcvs[name] = search\n",
    "        \n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "        \n",
    "for name, gs_est in sorted(gridcvs.items()):\n",
    "    print(50 * '-', '\\n')\n",
    "    print('Algorithm:', name)\n",
    "    print('    Inner loop:')\n",
    "    for train_ix, test_ix in cv_outer.split(X_scaled):\n",
    "        # split data\n",
    "        X_train, X_test = X_scaled[train_ix, :], X_scaled[test_ix, :]\n",
    "        y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "        result = gridcvs[name].fit(X_train, y_train) # run inner loop hyperparam tuning\n",
    "        \n",
    "        # get the best performing model fit on the whole training set\n",
    "        best_model = result.best_estimator_\n",
    "        # evaluate model on the hold out dataset\n",
    "        yhat = best_model.predict(X_test)\n",
    "        # evaluate the model\n",
    "        acc = accuracy_score(y_test, yhat)\n",
    "        # store the result\n",
    "        outer_results.append(acc)\n",
    "        # report progress\n",
    "        print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))     \n",
    "    # summarize the estimated performance of the model\n",
    "    print('\\n    Outer Loop:')\n",
    "    print('ACC : %.3f (%.3f)' % (mean(outer_results), std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
