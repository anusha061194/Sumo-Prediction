{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filtered_df = pd.read_excel(\"C:/Users/anush/Desktop/Torikumi_New.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['Rikishi1_career_wins'] = filtered_df.groupby(['Rikishi1']).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['Rikishi2_career_losses'] = filtered_df.groupby(['Rikishi2']).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_excel(\"C:/Users/anush/Desktop/Sumo Wrestling/PhysicalTraits_torikumi_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rikishi1_df = pd.DataFrame(columns=['Rikishi1', 'Rikishi1_career_wins'])\n",
    "for i in range(len(filtered_df)):\n",
    "    rikishi2 = str(filtered_df.iloc[i, 23])\n",
    "    rikishi1_df.loc[i] = str(filtered_df.iloc[i, 5])\n",
    "    if rikishi2 in rikishi1_df.values :\n",
    "        occur_len = len(rikishi1_df[rikishi1_df['Rikishi1'] == rikishi2])\n",
    "        filtered_df.loc[i,['Rikishi2_career_wins']] = occur_len\n",
    "    else :\n",
    "        occur_len = 0\n",
    "        filtered_df.loc[i,['Rikishi2_career_wins']] = occur_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_excel(\"C:/Users/anush/Desktop/Torikumi_New.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filtered_df = pd.read_excel(\"C:/Users/anush/Desktop/Torikumi_New.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical = (pd.notnull(filtered_df['Rikishi1_career_wins'])) & (pd.notnull(filtered_df['Rikishi2_career_wins'])) & (pd.notnull(filtered_df['Rikishi1_career_losses'])) & (pd.notnull(filtered_df['Rikishi2_career_losses']))  \n",
    "\n",
    "filtered_df = filtered_df[logical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: DTree\n",
      "    Inner loop:\n",
      ">acc=0.703, est=0.699, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      ">acc=0.699, est=0.700, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      ">acc=0.697, est=0.699, cfg={'criterion': 'entropy', 'max_depth': 9}\n",
      ">acc=0.700, est=0.698, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      ">acc=0.700, est=0.700, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      ">acc=0.690, est=0.698, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      ">acc=0.700, est=0.700, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      ">acc=0.694, est=0.699, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      ">acc=0.701, est=0.700, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      ">acc=0.696, est=0.701, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.698 (0.004)\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: GNB\n",
      "    Inner loop:\n",
      ">acc=0.651, est=0.647, cfg={'var_smoothing': 0.0023101297000831605}\n",
      ">acc=0.648, est=0.647, cfg={'var_smoothing': 0.0012328467394420659}\n",
      ">acc=0.654, est=0.646, cfg={'var_smoothing': 0.0001232846739442066}\n",
      ">acc=0.652, est=0.647, cfg={'var_smoothing': 8.111308307896872e-05}\n",
      ">acc=0.647, est=0.647, cfg={'var_smoothing': 0.001873817422860383}\n",
      ">acc=0.632, est=0.649, cfg={'var_smoothing': 0.0003511191734215131}\n",
      ">acc=0.651, est=0.647, cfg={'var_smoothing': 0.0015199110829529332}\n",
      ">acc=0.639, est=0.648, cfg={'var_smoothing': 0.001}\n",
      ">acc=0.650, est=0.647, cfg={'var_smoothing': 0.0003511191734215131}\n",
      ">acc=0.644, est=0.647, cfg={'var_smoothing': 0.001873817422860383}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.672 (0.026)\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: KNN\n",
      "    Inner loop:\n",
      ">acc=0.730, est=0.720, cfg={'n_neighbors': 9, 'p': 2}\n",
      ">acc=0.723, est=0.723, cfg={'n_neighbors': 9, 'p': 2}\n",
      ">acc=0.722, est=0.723, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.722, est=0.721, cfg={'n_neighbors': 7, 'p': 2}\n",
      ">acc=0.726, est=0.720, cfg={'n_neighbors': 9, 'p': 2}\n",
      ">acc=0.718, est=0.724, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.733, est=0.721, cfg={'n_neighbors': 9, 'p': 2}\n",
      ">acc=0.720, est=0.723, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.728, est=0.720, cfg={'n_neighbors': 9, 'p': 2}\n",
      ">acc=0.716, est=0.721, cfg={'n_neighbors': 9, 'p': 1}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.690 (0.032)\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: LR\n",
      "    Inner loop:\n",
      ">acc=0.657, est=0.659, cfg={'C': 0.1, 'penalty': 'l2'}\n",
      ">acc=0.661, est=0.659, cfg={'C': 0.01, 'penalty': 'l2'}\n",
      ">acc=0.659, est=0.659, cfg={'C': 0.1, 'penalty': 'l2'}\n",
      ">acc=0.669, est=0.658, cfg={'C': 1.0, 'penalty': 'l2'}\n",
      ">acc=0.665, est=0.659, cfg={'C': 10.0, 'penalty': 'l2'}\n",
      ">acc=0.645, est=0.661, cfg={'C': 1.0, 'penalty': 'l2'}\n",
      ">acc=0.661, est=0.659, cfg={'C': 1.0, 'penalty': 'l2'}\n",
      ">acc=0.656, est=0.660, cfg={'C': 10.0, 'penalty': 'l2'}\n",
      ">acc=0.663, est=0.659, cfg={'C': 0.01, 'penalty': 'l2'}\n",
      ">acc=0.658, est=0.659, cfg={'C': 0.01, 'penalty': 'l2'}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.682 (0.031)\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: SVM\n",
      "    Inner loop:\n",
      ">acc=0.659, est=0.658, cfg={'kernel': 'linear'}\n",
      ">acc=0.658, est=0.658, cfg={'kernel': 'linear'}\n",
      ">acc=0.663, est=0.658, cfg={'kernel': 'linear'}\n",
      ">acc=0.662, est=0.658, cfg={'kernel': 'linear'}\n",
      ">acc=0.665, est=0.657, cfg={'kernel': 'linear'}\n",
      ">acc=0.643, est=0.660, cfg={'kernel': 'linear'}\n",
      ">acc=0.662, est=0.658, cfg={'kernel': 'linear'}\n",
      ">acc=0.652, est=0.659, cfg={'kernel': 'linear'}\n",
      ">acc=0.663, est=0.658, cfg={'kernel': 'linear'}\n",
      ">acc=0.656, est=0.659, cfg={'kernel': 'linear'}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.677 (0.030)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create dataset\n",
    "#X_scaled, y = make_classification(n_samples=59817, n_features=24, random_state=1, n_informative=2, n_redundant=22)\n",
    "# configure the cross-validation procedure\n",
    "\n",
    "X = filtered_df.loc[:, ['Rikishi1_career_wins', 'Rikishi2_career_wins', 'Rikishi1_career_losses', 'Rikishi2_career_losses']]\n",
    "scaler = StandardScaler(copy=True, with_mean=False, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "y = filtered_df.loc[:, 'Label']  # labels, outcomes for first sumo (1 for wins, 0 for losses)\n",
    "\n",
    "\n",
    "# define the model\n",
    "clf1 = LogisticRegression(multi_class='multinomial',solver='newton-cg',random_state=1)\n",
    "clf2 = KNeighborsClassifier(algorithm='ball_tree',leaf_size=20)\n",
    "clf3 = DecisionTreeClassifier(random_state=1)\n",
    "clf4 = GaussianNB()  \n",
    "clf5 = SVC()\n",
    "    \n",
    "# define search space\n",
    "param_grid1 = [{'penalty': ['l2'],'C': np.power(10., np.arange(-4, 4))}]\n",
    "param_grid2 = [{'n_neighbors': list(range(1, 10)),'p': [1, 2]}]\n",
    "param_grid3 = [{'max_depth': list(range(1, 10)) + [None],'criterion': ['gini', 'entropy']}]\n",
    "param_grid4 = [{'var_smoothing': np.logspace(0,-9, num=100)}]\n",
    "param_grid5 = [{'kernel': ['linear']}]\n",
    "cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# define search    \n",
    "gridcvs = {}\n",
    "for pgrid, est, name in zip((param_grid1, param_grid2, param_grid3, param_grid4, param_grid5),(clf1, clf2, clf3, clf4, clf5),('LR', 'KNN', 'DTree', 'GNB', 'SVM')):\n",
    "    search = GridSearchCV(estimator=est,param_grid=pgrid,scoring='accuracy',n_jobs=-1,cv=cv_inner,verbose=0,refit=True)\n",
    "    gridcvs[name] = search\n",
    "        \n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "        \n",
    "for name, gs_est in sorted(gridcvs.items()):\n",
    "    print(50 * '-', '\\n')\n",
    "    print('Algorithm:', name)\n",
    "    print('    Inner loop:')\n",
    "    for train_ix, test_ix in cv_outer.split(X_scaled):\n",
    "        # split data\n",
    "        X_train, X_test = X_scaled[train_ix, :], X_scaled[test_ix, :]\n",
    "        y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "        result = gridcvs[name].fit(X_train, y_train) # run inner loop hyperparam tuning\n",
    "        \n",
    "        # get the best performing model fit on the whole training set\n",
    "        best_model = result.best_estimator_\n",
    "        # evaluate model on the hold out dataset\n",
    "        yhat = best_model.predict(X_test)\n",
    "        # evaluate the model\n",
    "        acc = accuracy_score(y_test, yhat)\n",
    "        # store the result\n",
    "        outer_results.append(acc)\n",
    "        # report progress\n",
    "        print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))     \n",
    "    # summarize the estimated performance of the model\n",
    "    print('\\n    Outer Loop:')\n",
    "    print('ACC : %.3f (%.3f)' % (mean(outer_results), std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
