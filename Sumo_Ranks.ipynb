{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filtered_df = pd.read_excel(\"C:/Users/anush/Desktop/Torikumi_New.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical = (pd.notnull(filtered_df['Rikishi1_modified_rank'])) & (pd.notnull(filtered_df['Rikishi2_modified_rank'])) \n",
    "\n",
    "filtered_df = filtered_df[logical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: DTree\n",
      "    Inner loop:\n",
      ">acc=0.576, est=0.586, cfg={'criterion': 'gini', 'max_depth': 8}\n",
      ">acc=0.574, est=0.585, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      ">acc=0.576, est=0.585, cfg={'criterion': 'entropy', 'max_depth': 9}\n",
      ">acc=0.587, est=0.584, cfg={'criterion': 'gini', 'max_depth': 6}\n",
      ">acc=0.586, est=0.585, cfg={'criterion': 'gini', 'max_depth': 6}\n",
      ">acc=0.590, est=0.583, cfg={'criterion': 'gini', 'max_depth': 9}\n",
      ">acc=0.583, est=0.584, cfg={'criterion': 'entropy', 'max_depth': 5}\n",
      ">acc=0.589, est=0.583, cfg={'criterion': 'gini', 'max_depth': 5}\n",
      ">acc=0.584, est=0.585, cfg={'criterion': 'entropy', 'max_depth': 9}\n",
      ">acc=0.587, est=0.584, cfg={'criterion': 'entropy', 'max_depth': 7}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.583 (0.006)\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: GNB\n",
      "    Inner loop:\n",
      ">acc=0.574, est=0.584, cfg={'var_smoothing': 1.0}\n",
      ">acc=0.572, est=0.584, cfg={'var_smoothing': 1.0}\n",
      ">acc=0.578, est=0.583, cfg={'var_smoothing': 1.0}\n",
      ">acc=0.585, est=0.583, cfg={'var_smoothing': 1.0}\n",
      ">acc=0.585, est=0.583, cfg={'var_smoothing': 1.0}\n",
      ">acc=0.586, est=0.583, cfg={'var_smoothing': 1.0}\n",
      ">acc=0.584, est=0.583, cfg={'var_smoothing': 1.0}\n",
      ">acc=0.591, est=0.582, cfg={'var_smoothing': 1.0}\n",
      ">acc=0.587, est=0.582, cfg={'var_smoothing': 1.0}\n",
      ">acc=0.586, est=0.582, cfg={'var_smoothing': 1.0}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.583 (0.006)\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: KNN\n",
      "    Inner loop:\n",
      ">acc=0.532, est=0.539, cfg={'n_neighbors': 9, 'p': 2}\n",
      ">acc=0.532, est=0.539, cfg={'n_neighbors': 9, 'p': 2}\n",
      ">acc=0.539, est=0.542, cfg={'n_neighbors': 9, 'p': 2}\n",
      ">acc=0.535, est=0.541, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.529, est=0.541, cfg={'n_neighbors': 9, 'p': 2}\n",
      ">acc=0.542, est=0.540, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.540, est=0.539, cfg={'n_neighbors': 9, 'p': 2}\n",
      ">acc=0.536, est=0.535, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.547, est=0.536, cfg={'n_neighbors': 9, 'p': 1}\n",
      ">acc=0.541, est=0.541, cfg={'n_neighbors': 9, 'p': 1}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.568 (0.022)\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: LR\n",
      "    Inner loop:\n",
      ">acc=0.574, est=0.584, cfg={'C': 0.0001, 'penalty': 'l2'}\n",
      ">acc=0.572, est=0.584, cfg={'C': 0.0001, 'penalty': 'l2'}\n",
      ">acc=0.578, est=0.583, cfg={'C': 0.0001, 'penalty': 'l2'}\n",
      ">acc=0.585, est=0.583, cfg={'C': 0.0001, 'penalty': 'l2'}\n",
      ">acc=0.585, est=0.583, cfg={'C': 0.0001, 'penalty': 'l2'}\n",
      ">acc=0.586, est=0.583, cfg={'C': 0.0001, 'penalty': 'l2'}\n",
      ">acc=0.584, est=0.583, cfg={'C': 0.0001, 'penalty': 'l2'}\n",
      ">acc=0.591, est=0.582, cfg={'C': 0.0001, 'penalty': 'l2'}\n",
      ">acc=0.587, est=0.582, cfg={'C': 0.0001, 'penalty': 'l2'}\n",
      ">acc=0.586, est=0.582, cfg={'C': 0.0001, 'penalty': 'l2'}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.572 (0.020)\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: SVM\n",
      "    Inner loop:\n",
      ">acc=0.574, est=0.584, cfg={'C': 1, 'kernel': 'linear'}\n",
      ">acc=0.572, est=0.584, cfg={'C': 1, 'kernel': 'linear'}\n",
      ">acc=0.578, est=0.583, cfg={'C': 1, 'kernel': 'linear'}\n",
      ">acc=0.585, est=0.583, cfg={'C': 1, 'kernel': 'linear'}\n",
      ">acc=0.585, est=0.583, cfg={'C': 1, 'kernel': 'linear'}\n",
      ">acc=0.586, est=0.583, cfg={'C': 1, 'kernel': 'linear'}\n",
      ">acc=0.584, est=0.583, cfg={'C': 1, 'kernel': 'linear'}\n",
      ">acc=0.591, est=0.582, cfg={'C': 1, 'kernel': 'linear'}\n",
      ">acc=0.587, est=0.582, cfg={'C': 1, 'kernel': 'linear'}\n",
      ">acc=0.586, est=0.582, cfg={'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "    Outer Loop:\n",
      "ACC : 0.574 (0.019)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create dataset\n",
    "#X_scaled, y = make_classification(n_samples=59817, n_features=24, random_state=1, n_informative=2, n_redundant=22)\n",
    "# configure the cross-validation procedure\n",
    "\n",
    "X = filtered_df.loc[:, ['Rikishi1_modified_rank', 'Rikishi2_modified_rank']]\n",
    "scaler = StandardScaler(copy=True, with_mean=False, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "y = filtered_df.loc[:, 'Label']  # labels, outcomes for first sumo (1 for wins, 0 for losses)\n",
    "\n",
    "# define the model\n",
    "clf1 = LogisticRegression(multi_class='multinomial',solver='newton-cg',random_state=1)\n",
    "clf2 = KNeighborsClassifier(algorithm='ball_tree',leaf_size=20)\n",
    "clf3 = DecisionTreeClassifier(random_state=1)\n",
    "clf4 = GaussianNB()  \n",
    "clf5 = SVC()\n",
    "    \n",
    "# define search space\n",
    "param_grid1 = [{'penalty': ['l2'],'C': np.power(10., np.arange(-4, 4))}]\n",
    "param_grid2 = [{'n_neighbors': list(range(1, 10)),'p': [1, 2]}]\n",
    "param_grid3 = [{'max_depth': list(range(1, 10)) + [None],'criterion': ['gini', 'entropy']}]\n",
    "param_grid4 = [{'var_smoothing': np.logspace(0,-9, num=100)}]\n",
    "param_grid5 = [{'kernel': ['linear'],'C': [1, 10]}]\n",
    "\n",
    "cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# define search    \n",
    "gridcvs = {}\n",
    "for pgrid, est, name in zip((param_grid1, param_grid2, param_grid3, param_grid4, param_grid5),(clf1, clf2, clf3, clf4, clf5),('LR', 'KNN', 'DTree', 'GNB', 'SVM')):\n",
    "    search = GridSearchCV(estimator=est,param_grid=pgrid,scoring='accuracy',n_jobs=-1,cv=cv_inner,verbose=0,refit=True)\n",
    "    gridcvs[name] = search\n",
    "        \n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "        \n",
    "for name, gs_est in sorted(gridcvs.items()):\n",
    "    print(50 * '-', '\\n')\n",
    "    print('Algorithm:', name)\n",
    "    print('    Inner loop:')\n",
    "    for train_ix, test_ix in cv_outer.split(X_scaled):\n",
    "        # split data\n",
    "        X_train, X_test = X_scaled[train_ix, :], X_scaled[test_ix, :]\n",
    "        y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "        result = gridcvs[name].fit(X_train, y_train) # run inner loop hyperparam tuning\n",
    "        \n",
    "        # get the best performing model fit on the whole training set\n",
    "        best_model = result.best_estimator_\n",
    "        # evaluate model on the hold out dataset\n",
    "        yhat = best_model.predict(X_test)\n",
    "        # evaluate the model\n",
    "        acc = accuracy_score(y_test, yhat)\n",
    "        # store the result\n",
    "        outer_results.append(acc)\n",
    "        # report progress\n",
    "        print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))     \n",
    "    # summarize the estimated performance of the model\n",
    "    print('\\n    Outer Loop:')\n",
    "    print('ACC : %.3f (%.3f)' % (mean(outer_results), std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
